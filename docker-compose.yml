x-spark-common: &spark-common
  image: apache/spark:3.5.0
  user: root
  networks:
    - de-network

x-airflow-common: &airflow-common
  image: apache/airflow:2.8.1
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3ZkkFSivT_HXyBq0zE2VdGvT4bU_XjFXv0=
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    - _AIRFLOW_DB_UPGRADE=true
    - _AIRFLOW_WWW_USER_CREATE=true
    - _AIRFLOW_WWW_USER_USERNAME=admin
    - _AIRFLOW_WWW_USER_PASSWORD=admin
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
  networks:
    - de-network
  depends_on:
    - postgres

services:
  # ----------------------------------------
  # Streaming Layer: Redpanda (Kafka)
  # ----------------------------------------
  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: redpanda
    command:
      - redpanda start
      - --smp 1
      - --memory 1G
      - --reserve-memory 0M
      - --overprovisioned
      - --node-id 0
      - --check=false
      - --kafka-addr PLAINTEXT://0.0.0.0:29092,OUTSIDE://0.0.0.0:9092
      - --advertise-kafka-addr PLAINTEXT://redpanda:29092,OUTSIDE://localhost:9092
      - --pandaproxy-addr 0.0.0.0:8082
      - --advertise-pandaproxy-addr localhost:8082
    ports:
      - "9092:9092"
      - "8081:8081"
      - "8082:8082"
    networks:
      - de-network

  # ----------------------------------------
  # Storage Layer: MinIO (S3)
  # ----------------------------------------
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=minio123
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - de-network

  mc:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c " until (mc alias set minio http://minio:9000 minio minio123); do echo 'Waiting for MinIO...'; sleep 5; done; mc mb --ignore-existing minio/lakehouse; mc mb --ignore-existing minio/checkpoint; echo 'MinIO buckets created'; "
    networks:
      - de-network

  # ----------------------------------------
  # Compute Layer: Spark
  # ----------------------------------------
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    user: root
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./:/opt/workspace
    networks:
      - de-network

  spark-worker:
    <<: *spark-common
    container_name: spark-worker
    volumes:
      - ./:/opt/workspace
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master

  # ----------------------------------------
  # Orchestration Layer: Airflow
  # ----------------------------------------
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    networks:
      - de-network

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8088:8080"
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler

networks:
  de-network:
    driver: bridge

volumes:
  minio_data:
